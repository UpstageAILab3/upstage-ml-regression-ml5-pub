{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ  ë¶€ë™ì‚° ì‹¤ê±°ë˜ê°€ ì˜ˆì¸¡ ëŒ€íšŒ - KKH - MODEL\n",
    "> - í•™ìŠµ, ì˜ˆì¸¡, í‰ê°€ë¥¼ ì§„í–‰í•œë‹¤.\n",
    "> - kimkihong / helpotcreator@gmail.com / Upstage AI Lab 3ê¸°\n",
    "> - 2024.07.16.í™” ~ 2024.07.19.ê¸ˆ 19:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "fe = fm.FontEntry(fname=r'font/NanumGothic.otf', name='NanumBarunGothic')\n",
    "fm.fontManager.ttflist.insert(0, fe)\n",
    "plt.rcParams.update({'font.size': 10, 'font.family': 'NanumBarunGothic'})\n",
    "plt.rc('font', family='NanumBarunGothic')\n",
    "import seaborn as sns\n",
    "\n",
    "# utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import warnings;warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import re\n",
    "import math\n",
    "\n",
    "# Model\n",
    "from sklearn.compose import TransformedTargetRegressor, ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer, LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor, CatBoost\n",
    "from category_encoders import TargetEncoder, OneHotEncoder, MEstimateEncoder, OrdinalEncoder, CatBoostEncoder\n",
    "\n",
    "# Optuna\n",
    "from optuna import create_study\n",
    "from optuna.integration import OptunaSearchCV\n",
    "from optuna.samplers import TPESampler\n",
    "import optuna\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "# ëª¨ë“  ì—´ì„ í‘œì‹œí•˜ë„ë¡ ì„¤ì •\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/kkh_train.csv', encoding='utf-8')\n",
    "test = pd.read_csv('data/kkh_test.csv', encoding='utf-8')\n",
    "loan = pd.read_csv('data/kkh_loan.csv', encoding='utf-8') # ì„œìš¸ì‹œ ê°€ê³„ëŒ€ì¶œê·œëª¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['ì„¸ëŒ€ë³„ì£¼ì°¨ëŒ€ìˆ˜'] = train['ì£¼ì°¨ëŒ€ìˆ˜'] / train['k-ì „ì²´ì„¸ëŒ€ìˆ˜']\n",
    "test['ì„¸ëŒ€ë³„ì£¼ì°¨ëŒ€ìˆ˜'] = test['ì£¼ì°¨ëŒ€ìˆ˜'] / test['k-ì „ì²´ì„¸ëŒ€ìˆ˜']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'ê³„ì•½ë…„ì›”'ê³¼ 'ë…„ì›”'ì´ ì¼ì¹˜í•˜ëŠ” ê²½ìš° 'ì„œìš¸ì‹œ_ê°€ê³„ëŒ€ì¶œ' ì •ë³´ë¥¼ trainì— ë³‘í•©\n",
    "train = train.merge(loan, how='left', left_on='ê³„ì•½ë…„ì›”', right_on='ë…„ì›”')\n",
    "# 'ë…„ì›”' ì—´ì€ í•„ìš” ì—†ìœ¼ë¯€ë¡œ ì‚­ì œ\n",
    "train.drop(columns=['ë…„ì›”'], inplace=True)\n",
    "\n",
    "test = test.merge(loan, how='left', left_on='ê³„ì•½ë…„ì›”', right_on='ë…„ì›”')\n",
    "test.drop(columns=['ë…„ì›”'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'ë™+ì•„íŒŒíŠ¸ëª…' ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”í•˜ì—¬ 'target' í”¼ì²˜ì˜ í‰ê·  ê°€ê²© ê³„ì‚°\n",
    "mean_target_per_group = train.groupby('ë™+ì•„íŒŒíŠ¸ëª…')['target'].mean()\n",
    "\n",
    "# í‰ê·  ê°€ê²©ì´ 200,000 ì´ìƒì¸ ê·¸ë£¹ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ìƒì„±\n",
    "high_price_groups = mean_target_per_group[mean_target_per_group >= 200000].index.tolist()\n",
    "\n",
    "# train ë°ì´í„°ì— 'top_apt' í”¼ì²˜ ì¶”ê°€\n",
    "train['top_apt'] = train['ë™+ì•„íŒŒíŠ¸ëª…'].apply(lambda x: 1 if x in high_price_groups else 0).astype('category')\n",
    "\n",
    "# test ë°ì´í„°ì— 'top_apt' í”¼ì²˜ ì¶”ê°€\n",
    "test['top_apt'] = test['ë™+ì•„íŒŒíŠ¸ëª…'].apply(lambda x: 1 if x in high_price_groups else 0).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['êµ­ë¯¼í‰ìˆ˜'] = train['ì „ìš©ë©´ì (ã¡)'].apply(lambda x: 1 if x <= 90 else 0)\n",
    "test['êµ­ë¯¼í‰ìˆ˜'] = test['ì „ìš©ë©´ì (ã¡)'].apply(lambda x: 1 if x <= 90 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_feature_list = ['ì•„íŒŒíŠ¸ëª…', 'ì „ìš©ë©´ì (ã¡)', 'ê³„ì•½ë…„ì›”', 'ì¸µ', 'ê±´ì¶•ë…„ë„', 'êµ¬', 'ë™', 'ë„ë¡œëª…', 'ì„¸ëŒ€ë³„ì£¼ì°¨ëŒ€ìˆ˜', 'ì¢Œí‘œX', 'ì¢Œí‘œY', 'target', 'top_apt', 'êµ­ë¯¼í‰ìˆ˜', '1ë²ˆì§¸_ê°€ê¹Œìš´_ì—­_ì´ë¦„', '1ë²ˆì§¸_ê°€ê¹Œìš´_ì—­_í˜¸ì„ ', '1ë²ˆì§¸_ê°€ê¹Œìš´_ì—­_ê±°ë¦¬', '5ë¶„ì´í•˜_ì—­_ê°œìˆ˜', '5ë¶„ì´ˆê³¼_10ë¶„ì´í•˜_ì—­_ê°œìˆ˜']\n",
    "selected_feature_list = ['ì•„íŒŒíŠ¸ëª…', 'ì „ìš©ë©´ì (ã¡)', 'ì„œìš¸ì‹œ_ê°€ê³„ëŒ€ì¶œ', 'ì¸µ', 'ê±´ì¶•ë…„ë„', 'êµ¬', 'ë™', 'ë„ë¡œëª…', 'ì„¸ëŒ€ë³„ì£¼ì°¨ëŒ€ìˆ˜', 'ì¢Œí‘œX', 'ì¢Œí‘œY', 'target', 'top_apt', 'êµ­ë¯¼í‰ìˆ˜', '1ë²ˆì§¸_ê°€ê¹Œìš´_ì—­_ì´ë¦„', '1ë²ˆì§¸_ê°€ê¹Œìš´_ì—­_í˜¸ì„ ', '1ë²ˆì§¸_ê°€ê¹Œìš´_ì—­_ê±°ë¦¬', '5ë¶„ì´í•˜_ì—­_ê°œìˆ˜', '5ë¶„ì´ˆê³¼_10ë¶„ì´í•˜_ì—­_ê°œìˆ˜']\n",
    "train = train[selected_feature_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('data/kkh_train_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ì•„íŒŒíŠ¸ëª…</th>\n",
       "      <th>ì „ìš©ë©´ì (ã¡)</th>\n",
       "      <th>ê³„ì•½ë…„ì›”</th>\n",
       "      <th>ì¸µ</th>\n",
       "      <th>ê±´ì¶•ë…„ë„</th>\n",
       "      <th>êµ¬</th>\n",
       "      <th>ë™</th>\n",
       "      <th>ë„ë¡œëª…</th>\n",
       "      <th>ì„¸ëŒ€ë³„ì£¼ì°¨ëŒ€ìˆ˜</th>\n",
       "      <th>ì¢Œí‘œX</th>\n",
       "      <th>ì¢Œí‘œY</th>\n",
       "      <th>target</th>\n",
       "      <th>top_apt</th>\n",
       "      <th>êµ­ë¯¼í‰ìˆ˜</th>\n",
       "      <th>1ë²ˆì§¸_ê°€ê¹Œìš´_ì—­_ì´ë¦„</th>\n",
       "      <th>1ë²ˆì§¸_ê°€ê¹Œìš´_ì—­_í˜¸ì„ </th>\n",
       "      <th>1ë²ˆì§¸_ê°€ê¹Œìš´_ì—­_ê±°ë¦¬</th>\n",
       "      <th>5ë¶„ì´í•˜_ì—­_ê°œìˆ˜</th>\n",
       "      <th>5ë¶„ì´ˆê³¼_10ë¶„ì´í•˜_ì—­_ê°œìˆ˜</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ê°œí¬6ì°¨ìš°ì„±</td>\n",
       "      <td>79.97</td>\n",
       "      <td>201712</td>\n",
       "      <td>3</td>\n",
       "      <td>1987</td>\n",
       "      <td>ê°•ë‚¨êµ¬</td>\n",
       "      <td>ê°œí¬ë™</td>\n",
       "      <td>ì–¸ì£¼ë¡œ 3</td>\n",
       "      <td>0.970370</td>\n",
       "      <td>127.056859</td>\n",
       "      <td>37.476276</td>\n",
       "      <td>124000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>êµ¬ë£¡</td>\n",
       "      <td>ë¶„ë‹¹ì„ </td>\n",
       "      <td>1187.672025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ê°œí¬6ì°¨ìš°ì„±</td>\n",
       "      <td>79.97</td>\n",
       "      <td>201712</td>\n",
       "      <td>4</td>\n",
       "      <td>1987</td>\n",
       "      <td>ê°•ë‚¨êµ¬</td>\n",
       "      <td>ê°œí¬ë™</td>\n",
       "      <td>ì–¸ì£¼ë¡œ 3</td>\n",
       "      <td>0.970370</td>\n",
       "      <td>127.056859</td>\n",
       "      <td>37.476276</td>\n",
       "      <td>123500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>êµ¬ë£¡</td>\n",
       "      <td>ë¶„ë‹¹ì„ </td>\n",
       "      <td>1187.672025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ê°œí¬6ì°¨ìš°ì„±</td>\n",
       "      <td>54.98</td>\n",
       "      <td>201712</td>\n",
       "      <td>5</td>\n",
       "      <td>1987</td>\n",
       "      <td>ê°•ë‚¨êµ¬</td>\n",
       "      <td>ê°œí¬ë™</td>\n",
       "      <td>ì–¸ì£¼ë¡œ 3</td>\n",
       "      <td>0.970370</td>\n",
       "      <td>127.056859</td>\n",
       "      <td>37.476276</td>\n",
       "      <td>91500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>êµ¬ë£¡</td>\n",
       "      <td>ë¶„ë‹¹ì„ </td>\n",
       "      <td>1187.672025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ê°œí¬6ì°¨ìš°ì„±</td>\n",
       "      <td>79.97</td>\n",
       "      <td>201801</td>\n",
       "      <td>4</td>\n",
       "      <td>1987</td>\n",
       "      <td>ê°•ë‚¨êµ¬</td>\n",
       "      <td>ê°œí¬ë™</td>\n",
       "      <td>ì–¸ì£¼ë¡œ 3</td>\n",
       "      <td>0.970370</td>\n",
       "      <td>127.056859</td>\n",
       "      <td>37.476276</td>\n",
       "      <td>130000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>êµ¬ë£¡</td>\n",
       "      <td>ë¶„ë‹¹ì„ </td>\n",
       "      <td>1187.672025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ê°œí¬6ì°¨ìš°ì„±</td>\n",
       "      <td>79.97</td>\n",
       "      <td>201801</td>\n",
       "      <td>2</td>\n",
       "      <td>1987</td>\n",
       "      <td>ê°•ë‚¨êµ¬</td>\n",
       "      <td>ê°œí¬ë™</td>\n",
       "      <td>ì–¸ì£¼ë¡œ 3</td>\n",
       "      <td>0.970370</td>\n",
       "      <td>127.056859</td>\n",
       "      <td>37.476276</td>\n",
       "      <td>117000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>êµ¬ë£¡</td>\n",
       "      <td>ë¶„ë‹¹ì„ </td>\n",
       "      <td>1187.672025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118817</th>\n",
       "      <td>ê°ˆí˜„í˜„ëŒ€</td>\n",
       "      <td>59.94</td>\n",
       "      <td>200707</td>\n",
       "      <td>11</td>\n",
       "      <td>1998</td>\n",
       "      <td>ì€í‰êµ¬</td>\n",
       "      <td>êµ¬ì‚°ë™</td>\n",
       "      <td>ì„œì˜¤ë¦‰ë¡œ21ê¸¸ 36</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>126.905543</td>\n",
       "      <td>37.612989</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>êµ¬ì‚°</td>\n",
       "      <td>6í˜¸ì„ </td>\n",
       "      <td>1048.367837</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118818</th>\n",
       "      <td>ê°ˆí˜„í˜„ëŒ€</td>\n",
       "      <td>59.94</td>\n",
       "      <td>200708</td>\n",
       "      <td>10</td>\n",
       "      <td>1998</td>\n",
       "      <td>ì€í‰êµ¬</td>\n",
       "      <td>êµ¬ì‚°ë™</td>\n",
       "      <td>ì„œì˜¤ë¦‰ë¡œ21ê¸¸ 36</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>126.905543</td>\n",
       "      <td>37.612989</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>êµ¬ì‚°</td>\n",
       "      <td>6í˜¸ì„ </td>\n",
       "      <td>1048.367837</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118819</th>\n",
       "      <td>ê°ˆí˜„í˜„ëŒ€</td>\n",
       "      <td>84.83</td>\n",
       "      <td>200708</td>\n",
       "      <td>20</td>\n",
       "      <td>1998</td>\n",
       "      <td>ì€í‰êµ¬</td>\n",
       "      <td>êµ¬ì‚°ë™</td>\n",
       "      <td>ì„œì˜¤ë¦‰ë¡œ21ê¸¸ 36</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>126.905543</td>\n",
       "      <td>37.612989</td>\n",
       "      <td>28000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>êµ¬ì‚°</td>\n",
       "      <td>6í˜¸ì„ </td>\n",
       "      <td>1048.367837</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118820</th>\n",
       "      <td>ê°ˆí˜„í˜„ëŒ€</td>\n",
       "      <td>84.83</td>\n",
       "      <td>200709</td>\n",
       "      <td>8</td>\n",
       "      <td>1998</td>\n",
       "      <td>ì€í‰êµ¬</td>\n",
       "      <td>êµ¬ì‚°ë™</td>\n",
       "      <td>ì„œì˜¤ë¦‰ë¡œ21ê¸¸ 36</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>126.905543</td>\n",
       "      <td>37.612989</td>\n",
       "      <td>29000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>êµ¬ì‚°</td>\n",
       "      <td>6í˜¸ì„ </td>\n",
       "      <td>1048.367837</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118821</th>\n",
       "      <td>ë¬µì •</td>\n",
       "      <td>52.46</td>\n",
       "      <td>200701</td>\n",
       "      <td>5</td>\n",
       "      <td>1981</td>\n",
       "      <td>ì¤‘êµ¬</td>\n",
       "      <td>ë¬µì •ë™</td>\n",
       "      <td>ì„œì• ë¡œ1ê¸¸ 34</td>\n",
       "      <td>0.368852</td>\n",
       "      <td>127.000034</td>\n",
       "      <td>37.560695</td>\n",
       "      <td>13250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ë™ëŒ€ì…êµ¬</td>\n",
       "      <td>3í˜¸ì„ </td>\n",
       "      <td>523.705597</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1118822 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ì•„íŒŒíŠ¸ëª…  ì „ìš©ë©´ì (ã¡)    ê³„ì•½ë…„ì›”   ì¸µ  ê±´ì¶•ë…„ë„    êµ¬    ë™         ë„ë¡œëª…   ì„¸ëŒ€ë³„ì£¼ì°¨ëŒ€ìˆ˜  \\\n",
       "0        ê°œí¬6ì°¨ìš°ì„±    79.97  201712   3  1987  ê°•ë‚¨êµ¬  ê°œí¬ë™       ì–¸ì£¼ë¡œ 3  0.970370   \n",
       "1        ê°œí¬6ì°¨ìš°ì„±    79.97  201712   4  1987  ê°•ë‚¨êµ¬  ê°œí¬ë™       ì–¸ì£¼ë¡œ 3  0.970370   \n",
       "2        ê°œí¬6ì°¨ìš°ì„±    54.98  201712   5  1987  ê°•ë‚¨êµ¬  ê°œí¬ë™       ì–¸ì£¼ë¡œ 3  0.970370   \n",
       "3        ê°œí¬6ì°¨ìš°ì„±    79.97  201801   4  1987  ê°•ë‚¨êµ¬  ê°œí¬ë™       ì–¸ì£¼ë¡œ 3  0.970370   \n",
       "4        ê°œí¬6ì°¨ìš°ì„±    79.97  201801   2  1987  ê°•ë‚¨êµ¬  ê°œí¬ë™       ì–¸ì£¼ë¡œ 3  0.970370   \n",
       "...         ...      ...     ...  ..   ...  ...  ...         ...       ...   \n",
       "1118817    ê°ˆí˜„í˜„ëŒ€    59.94  200707  11  1998  ì€í‰êµ¬  êµ¬ì‚°ë™  ì„œì˜¤ë¦‰ë¡œ21ê¸¸ 36  1.000000   \n",
       "1118818    ê°ˆí˜„í˜„ëŒ€    59.94  200708  10  1998  ì€í‰êµ¬  êµ¬ì‚°ë™  ì„œì˜¤ë¦‰ë¡œ21ê¸¸ 36  1.000000   \n",
       "1118819    ê°ˆí˜„í˜„ëŒ€    84.83  200708  20  1998  ì€í‰êµ¬  êµ¬ì‚°ë™  ì„œì˜¤ë¦‰ë¡œ21ê¸¸ 36  1.000000   \n",
       "1118820    ê°ˆí˜„í˜„ëŒ€    84.83  200709   8  1998  ì€í‰êµ¬  êµ¬ì‚°ë™  ì„œì˜¤ë¦‰ë¡œ21ê¸¸ 36  1.000000   \n",
       "1118821      ë¬µì •    52.46  200701   5  1981   ì¤‘êµ¬  ë¬µì •ë™    ì„œì• ë¡œ1ê¸¸ 34  0.368852   \n",
       "\n",
       "                ì¢Œí‘œX        ì¢Œí‘œY  target top_apt  êµ­ë¯¼í‰ìˆ˜ 1ë²ˆì§¸_ê°€ê¹Œìš´_ì—­_ì´ë¦„  \\\n",
       "0        127.056859  37.476276  124000       0     1           êµ¬ë£¡   \n",
       "1        127.056859  37.476276  123500       0     1           êµ¬ë£¡   \n",
       "2        127.056859  37.476276   91500       0     1           êµ¬ë£¡   \n",
       "3        127.056859  37.476276  130000       0     1           êµ¬ë£¡   \n",
       "4        127.056859  37.476276  117000       0     1           êµ¬ë£¡   \n",
       "...             ...        ...     ...     ...   ...          ...   \n",
       "1118817  126.905543  37.612989   20000       0     1           êµ¬ì‚°   \n",
       "1118818  126.905543  37.612989   20000       0     1           êµ¬ì‚°   \n",
       "1118819  126.905543  37.612989   28000       0     1           êµ¬ì‚°   \n",
       "1118820  126.905543  37.612989   29000       0     1           êµ¬ì‚°   \n",
       "1118821  127.000034  37.560695   13250       0     1         ë™ëŒ€ì…êµ¬   \n",
       "\n",
       "        1ë²ˆì§¸_ê°€ê¹Œìš´_ì—­_í˜¸ì„   1ë²ˆì§¸_ê°€ê¹Œìš´_ì—­_ê±°ë¦¬  5ë¶„ì´í•˜_ì—­_ê°œìˆ˜  5ë¶„ì´ˆê³¼_10ë¶„ì´í•˜_ì—­_ê°œìˆ˜  \n",
       "0                ë¶„ë‹¹ì„    1187.672025          0                0  \n",
       "1                ë¶„ë‹¹ì„    1187.672025          0                0  \n",
       "2                ë¶„ë‹¹ì„    1187.672025          0                0  \n",
       "3                ë¶„ë‹¹ì„    1187.672025          0                0  \n",
       "4                ë¶„ë‹¹ì„    1187.672025          0                0  \n",
       "...              ...           ...        ...              ...  \n",
       "1118817          6í˜¸ì„    1048.367837          0                0  \n",
       "1118818          6í˜¸ì„    1048.367837          0                0  \n",
       "1118819          6í˜¸ì„    1048.367837          0                0  \n",
       "1118820          6í˜¸ì„    1048.367837          0                0  \n",
       "1118821          3í˜¸ì„     523.705597          0                4  \n",
       "\n",
       "[1118822 rows x 19 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def impute_missing_values(df):\n",
    "    # ìˆ˜ì¹˜í˜• í”¼ì²˜ì™€ ë²”ì£¼í˜• í”¼ì²˜ êµ¬ë¶„\n",
    "    numeric_features = df.select_dtypes(include=[np.number]).columns\n",
    "    categorical_features = df.select_dtypes(include=[object]).columns\n",
    "    \n",
    "    # ìˆ˜ì¹˜í˜• í”¼ì²˜ì˜ ê²°ì¸¡ì¹˜ë¥¼ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´\n",
    "    # for feature in numeric_features:\n",
    "    #     mean_value = df[feature].mean()\n",
    "    #     df[feature].fillna(mean_value, inplace=True)\n",
    "    \n",
    "    # ìˆ˜ì¹˜í˜• í”¼ì²˜ì˜ ê²°ì¸¡ì¹˜ë¥¼ -999ìœ¼ë¡œ ëŒ€ì²´\n",
    "    for feature in numeric_features:\n",
    "        df[feature].fillna(-999, inplace=True)\n",
    "    \n",
    "    # ë²”ì£¼í˜• í”¼ì²˜ì˜ ê²°ì¸¡ì¹˜ë¥¼ 'Missing'ìœ¼ë¡œ ëŒ€ì²´\n",
    "    for feature in categorical_features:\n",
    "        df[feature].fillna('Missing', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "impute_missing_values(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•„íŒŒíŠ¸ëª…               0.0\n",
      "ì „ìš©ë©´ì (ã¡)            0.0\n",
      "ê³„ì•½ë…„ì›”               0.0\n",
      "ì¸µ                  0.0\n",
      "ê±´ì¶•ë…„ë„               0.0\n",
      "êµ¬                  0.0\n",
      "ë™                  0.0\n",
      "ë„ë¡œëª…                0.0\n",
      "ì„¸ëŒ€ë³„ì£¼ì°¨ëŒ€ìˆ˜            0.0\n",
      "ì¢Œí‘œX                0.0\n",
      "ì¢Œí‘œY                0.0\n",
      "target             0.0\n",
      "top_apt            0.0\n",
      "êµ­ë¯¼í‰ìˆ˜               0.0\n",
      "1ë²ˆì§¸_ê°€ê¹Œìš´_ì—­_ì´ë¦„       0.0\n",
      "1ë²ˆì§¸_ê°€ê¹Œìš´_ì—­_í˜¸ì„        0.0\n",
      "1ë²ˆì§¸_ê°€ê¹Œìš´_ì—­_ê±°ë¦¬       0.0\n",
      "5ë¶„ì´í•˜_ì—­_ê°œìˆ˜          0.0\n",
      "5ë¶„ì´ˆê³¼_10ë¶„ì´í•˜_ì—­_ê°œìˆ˜    0.0\n"
     ]
    }
   ],
   "source": [
    "print((train.isnull().mean() * 100).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[~train['ì¸µ'].isin([-2, 65])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['ê³„ì•½ë…„ì›”'] >= 201801]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target         --> target\n",
      "Numeric Cols   --> ['ì „ìš©ë©´ì (ã¡)', 'ê³„ì•½ë…„ì›”', 'ì¸µ', 'ê±´ì¶•ë…„ë„', 'ì„¸ëŒ€ë³„ì£¼ì°¨ëŒ€ìˆ˜', 'ì¢Œí‘œX', 'ì¢Œí‘œY', 'êµ­ë¯¼í‰ìˆ˜', '1ë²ˆì§¸_ê°€ê¹Œìš´_ì—­_ê±°ë¦¬', '5ë¶„ì´í•˜_ì—­_ê°œìˆ˜', '5ë¶„ì´ˆê³¼_10ë¶„ì´í•˜_ì—­_ê°œìˆ˜']\n",
      "Categoric Cols --> ['ì•„íŒŒíŠ¸ëª…', 'êµ¬', 'ë™', 'ë„ë¡œëª…', 'top_apt', '1ë²ˆì§¸_ê°€ê¹Œìš´_ì—­_ì´ë¦„', '1ë²ˆì§¸_ê°€ê¹Œìš´_ì—­_í˜¸ì„ ']\n"
     ]
    }
   ],
   "source": [
    "SEED = 1053682552\n",
    "\n",
    "# TARGET ì •ì˜\n",
    "TARGET = 'target'\n",
    "\n",
    "# NUMERIC_COLS ê³„ì‚°: TARGETì„ ì œì™¸í•œ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸\n",
    "NUMERIC_COLS = [col for col in train.select_dtypes(include=[float, int]).columns if col != TARGET]\n",
    "\n",
    "# CAT_COLS ê³„ì‚°: NUMERIC_COLSë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸\n",
    "CAT_COLS = [col for col in train.columns if col not in NUMERIC_COLS + [TARGET]]\n",
    "\n",
    "print(f'Target         --> {TARGET}')\n",
    "print(f'Numeric Cols   --> {NUMERIC_COLS}')\n",
    "print(f'Categoric Cols --> {CAT_COLS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 12:59:15,576] A new study created in memory with name: no-name-cd58740c-8904-422e-8ad4-7f121dd2e580\n",
      "[I 2024-07-18 13:00:20,648] Trial 0 finished with value: 2254905188.3463016 and parameters: {'n_estimators': 828, 'learning_rate': 0.0003798782534911095, 'max_depth': 13, 'min_child_weight': 0.8246544242693233, 'subsample': 0.9927612315491489, 'colsample_bytree': 0.8526943846115274, 'gamma': 0.8904275349929992, 'alpha': 0.5057309506977974}. Best is trial 0 with value: 2254905188.3463016.\n",
      "[I 2024-07-18 13:00:28,515] Trial 1 finished with value: 1303550592.6085694 and parameters: {'n_estimators': 928, 'learning_rate': 0.0011874581171232713, 'max_depth': 5, 'min_child_weight': 3.838365619480914, 'subsample': 0.5795192745561082, 'colsample_bytree': 0.9808270454430227, 'gamma': 0.3956089060022762, 'alpha': 0.0005019860496167036}. Best is trial 1 with value: 1303550592.6085694.\n",
      "[I 2024-07-18 13:00:41,176] Trial 2 finished with value: 107839029.10775214 and parameters: {'n_estimators': 962, 'learning_rate': 0.023455379614063958, 'max_depth': 10, 'min_child_weight': 71.7263968579553, 'subsample': 0.8224766601569622, 'colsample_bytree': 0.9829533726947919, 'gamma': 0.9166076586984225, 'alpha': 97.31612494508994}. Best is trial 2 with value: 107839029.10775214.\n",
      "[I 2024-07-18 13:00:48,032] Trial 3 finished with value: 1436113050.7004046 and parameters: {'n_estimators': 572, 'learning_rate': 0.001463166518894126, 'max_depth': 7, 'min_child_weight': 0.0039064728761205245, 'subsample': 0.8491368548329773, 'colsample_bytree': 0.586280843618898, 'gamma': 0.9381647413444264, 'alpha': 42.7083101169966}. Best is trial 2 with value: 107839029.10775214.\n",
      "[I 2024-07-18 13:03:15,082] Trial 4 finished with value: 312642795.57746637 and parameters: {'n_estimators': 849, 'learning_rate': 0.002376372204300129, 'max_depth': 19, 'min_child_weight': 4.815062946604797, 'subsample': 0.6088602759025249, 'colsample_bytree': 0.555119526387431, 'gamma': 1.7773401202903318, 'alpha': 6.434902789471849}. Best is trial 2 with value: 107839029.10775214.\n",
      "[I 2024-07-18 13:04:13,698] Trial 5 finished with value: 193126839.6906959 and parameters: {'n_estimators': 805, 'learning_rate': 0.0031466891670029356, 'max_depth': 14, 'min_child_weight': 17.23843415960693, 'subsample': 0.8498923344198284, 'colsample_bytree': 0.683305557146062, 'gamma': 0.0005433497025964459, 'alpha': 27.471173727725297}. Best is trial 2 with value: 107839029.10775214.\n",
      "[I 2024-07-18 13:08:20,451] Trial 6 finished with value: 177047256.3871414 and parameters: {'n_estimators': 749, 'learning_rate': 0.0035958882487779863, 'max_depth': 18, 'min_child_weight': 0.8143514163217578, 'subsample': 0.8995781600358066, 'colsample_bytree': 0.6594165424286005, 'gamma': 0.000533448571293675, 'alpha': 0.00819585622902992}. Best is trial 2 with value: 107839029.10775214.\n",
      "[I 2024-07-18 13:08:27,736] Trial 7 finished with value: 395964680.7704469 and parameters: {'n_estimators': 477, 'learning_rate': 0.0045415517145289235, 'max_depth': 8, 'min_child_weight': 0.01795072666128742, 'subsample': 0.5558737332955109, 'colsample_bytree': 0.9628289890591709, 'gamma': 0.0002526096783084547, 'alpha': 0.005312280079701285}. Best is trial 2 with value: 107839029.10775214.\n",
      "[I 2024-07-18 13:10:25,209] Trial 8 finished with value: 102968395.63492388 and parameters: {'n_estimators': 565, 'learning_rate': 0.04223731676206321, 'max_depth': 17, 'min_child_weight': 0.0050395281289352944, 'subsample': 0.6748193915025716, 'colsample_bytree': 0.575666250505291, 'gamma': 0.00025338839768089717, 'alpha': 0.06392606729577881}. Best is trial 8 with value: 102968395.63492388.\n",
      "[I 2024-07-18 13:10:37,963] Trial 9 finished with value: 734496757.7816002 and parameters: {'n_estimators': 493, 'learning_rate': 0.0024471368348444157, 'max_depth': 10, 'min_child_weight': 3.5025405999238504, 'subsample': 0.8883513052801084, 'colsample_bytree': 0.6883506184890231, 'gamma': 2.498510480823198, 'alpha': 0.010050360402900242}. Best is trial 8 with value: 102968395.63492388.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@ XGBoost best params: {'n_estimators': 565, 'learning_rate': 0.04223731676206321, 'max_depth': 17, 'min_child_weight': 0.0050395281289352944, 'subsample': 0.6748193915025716, 'colsample_bytree': 0.575666250505291, 'gamma': 0.00025338839768089717, 'alpha': 0.06392606729577881}\n",
      "@@ model: XGBoost  /  R2: 0.9639  /  RMSE: 11059.5517\n"
     ]
    }
   ],
   "source": [
    "# # ë°ì´í„° ì¤€ë¹„\n",
    "# X = train.drop(columns=['target'])\n",
    "# y = train['target']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "\n",
    "# # ë²”ì£¼í˜• ì—´ì— ëŒ€í•œ ë ˆì´ë¸” ì¸ì½”ë”©\n",
    "# def label_encode_columns(X, cols):\n",
    "#     for col in cols:\n",
    "#         le = LabelEncoder()\n",
    "#         X[col] = le.fit_transform(X[col])\n",
    "#     return X\n",
    "\n",
    "# # ì „ì²˜ë¦¬ ë° ëª¨ë¸ íŒŒì´í”„ë¼ì¸ ì„¤ì •\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', StandardScaler(), NUMERIC_COLS),\n",
    "#         ('cat', FunctionTransformer(label_encode_columns, kw_args={'cols': CAT_COLS}), CAT_COLS)\n",
    "#     ], remainder='passthrough')\n",
    "\n",
    "# # ì˜µí‹°ë§ˆì´ì €ë¥¼ ìœ„í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê³µê°„ ì„¤ì •\n",
    "# # def objective_xgb(trial):\n",
    "# #     model = XGBRegressor(\n",
    "# #         n_estimators=trial.suggest_int('n_estimators', 300, 800),\n",
    "# #         learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
    "# #         max_depth=trial.suggest_int('max_depth', 6, 20),\n",
    "# #         alpha=trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
    "# #         random_state=SEED\n",
    "# #     )\n",
    "# #     pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "# #     kf = KFold(n_splits=3, shuffle=True, random_state=SEED)\n",
    "# #     cv_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
    "# #     return -np.mean(cv_scores)\n",
    "# def objective_xgb(trial):\n",
    "#     model = XGBRegressor(\n",
    "#         n_estimators=trial.suggest_int('n_estimators', 300, 1000),\n",
    "#         learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
    "#         max_depth=trial.suggest_int('max_depth', 5, 24),\n",
    "#         min_child_weight=trial.suggest_loguniform('min_child_weight', 1e-3, 1e2),\n",
    "#         subsample=trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "#         colsample_bytree=trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
    "#         gamma=trial.suggest_loguniform('gamma', 1e-4, 1e1),\n",
    "#         alpha=trial.suggest_loguniform('alpha', 1e-4, 1e2),\n",
    "#         random_state=SEED\n",
    "#     )\n",
    "#     pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "#     kf = KFold(n_splits=2, shuffle=True, random_state=SEED)\n",
    "#     cv_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
    "#     return -np.mean(cv_scores)\n",
    "\n",
    "# def objective_cat(trial):\n",
    "#     model = CatBoostRegressor(\n",
    "#         iterations=trial.suggest_int('iterations', 300, 800),\n",
    "#         learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n",
    "#         depth=trial.suggest_int('depth', 6, 20),\n",
    "#         random_state=SEED,\n",
    "#         verbose=0\n",
    "#     )\n",
    "#     pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "#     kf = KFold(n_splits=3, shuffle=True, random_state=SEED)\n",
    "#     cv_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
    "#     return -np.mean(cv_scores)\n",
    "\n",
    "# # ì˜µí‹°ë§ˆì´ì € ì„¤ì • ë° ìµœì í™”\n",
    "# def optimize_model(objective_function, n_trials):\n",
    "#     study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=SEED))\n",
    "#     study.optimize(objective_function, n_trials=n_trials)\n",
    "#     return study.best_params\n",
    "\n",
    "# # ê° ëª¨ë¸ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”\n",
    "# n_trials = 10\n",
    "\n",
    "# xgb_best_params = optimize_model(objective_xgb, n_trials)\n",
    "# print(\"@@ XGBoost best params:\", xgb_best_params)\n",
    "\n",
    "# # cat_best_params = optimize_model(objective_cat, n_trials)\n",
    "# # print(\"@@ CatBoost best params:\", cat_best_params)\n",
    "\n",
    "# # ëª¨ë¸ ì •ì˜, í•™ìŠµ, ì˜ˆì¸¡, í‰ê°€\n",
    "# results = {}\n",
    "# kf = KFold(n_splits=3, shuffle=True, random_state=SEED)\n",
    "\n",
    "# for model_name, model_class, best_params in [\n",
    "#     ('XGBoost', XGBRegressor, xgb_best_params),\n",
    "#     # ('CatBoost', CatBoostRegressor, cat_best_params)\n",
    "# ]:\n",
    "#     model = model_class(**best_params)\n",
    "#     pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "#     cv_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
    "#     rmse = np.sqrt(-np.mean(cv_scores))\n",
    "#     pipeline.fit(X_train, y_train)\n",
    "#     y_pred = pipeline.predict(X_test)\n",
    "#     r2 = r2_score(y_test, y_pred)\n",
    "#     results[model_name] = {'R2 Score': r2, 'RMSE': rmse}\n",
    "\n",
    "# # ê²°ê³¼ ì¶œë ¥\n",
    "# for model_name, metrics in results.items():\n",
    "#     print(f\"@@ model: {model_name}  /  R2: {metrics['R2 Score']:.4f}  /  RMSE: {metrics['RMSE']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ì¤€ë¹„\n",
    "X = train.drop(columns=['target'])\n",
    "y = train['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "\n",
    "# ë²”ì£¼í˜• ì—´ì— ëŒ€í•œ ë ˆì´ë¸” ì¸ì½”ë”©\n",
    "def label_encode_columns(X, cols):\n",
    "    for col in cols:\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "    return X\n",
    "\n",
    "# ì „ì²˜ë¦¬ ë° ëª¨ë¸ íŒŒì´í”„ë¼ì¸ ì„¤ì •\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), NUMERIC_COLS),\n",
    "        ('cat', FunctionTransformer(label_encode_columns, kw_args={'cols': CAT_COLS}), CAT_COLS)\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "# ëª¨ë¸ ì •ì˜, í•™ìŠµ, ì˜ˆì¸¡, í‰ê°€\n",
    "results = {}\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=SEED)\n",
    "\n",
    "model = RandomForestRegressor(random_state=SEED)\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
    "rmse = np.sqrt(-np.mean(cv_scores))\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "results['RandomForest'] = {'R2 Score': r2, 'RMSE': rmse}\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"@@ model: {model_name}  /  R2: {metrics['R2 Score']:.4f}  /  RMSE: {metrics['RMSE']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 565, 'learning_rate': 0.04223731676206321, 'max_depth': 17, 'min_child_weight': 0.0050395281289352944, 'subsample': 0.6748193915025716, 'colsample_bytree': 0.575666250505291, 'gamma': 0.00025338839768089717, 'alpha': 0.06392606729577881}\n",
      "======================\n"
     ]
    }
   ],
   "source": [
    "# print(xgb_best_params)\n",
    "# print('======================')\n",
    "# print(cat_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_feature_list = ['ì•„íŒŒíŠ¸ëª…', 'ì „ìš©ë©´ì (ã¡)', 'ê³„ì•½ë…„ì›”', 'ì¸µ', 'ê±´ì¶•ë…„ë„', 'êµ¬', 'ë™', 'ë„ë¡œëª…', 'ì„¸ëŒ€ë³„ì£¼ì°¨ëŒ€ìˆ˜', 'ì¢Œí‘œX', 'ì¢Œí‘œY', 'top_apt', 'êµ­ë¯¼í‰ìˆ˜', '1ë²ˆì§¸_ê°€ê¹Œìš´_ì—­_ì´ë¦„', '1ë²ˆì§¸_ê°€ê¹Œìš´_ì—­_í˜¸ì„ ', '1ë²ˆì§¸_ê°€ê¹Œìš´_ì—­_ê±°ë¦¬', '5ë¶„ì´í•˜_ì—­_ê°œìˆ˜', '5ë¶„ì´ˆê³¼_10ë¶„ì´í•˜_ì—­_ê°œìˆ˜']\n",
    "selected_feature_list = ['ì•„íŒŒíŠ¸ëª…', 'ì „ìš©ë©´ì (ã¡)', 'ì„œìš¸ì‹œ_ê°€ê³„ëŒ€ì¶œ', 'ì¸µ', 'ê±´ì¶•ë…„ë„', 'êµ¬', 'ë™', 'ë„ë¡œëª…', 'ì„¸ëŒ€ë³„ì£¼ì°¨ëŒ€ìˆ˜', 'ì¢Œí‘œX', 'ì¢Œí‘œY', 'top_apt', 'êµ­ë¯¼í‰ìˆ˜', '1ë²ˆì§¸_ê°€ê¹Œìš´_ì—­_ì´ë¦„', '1ë²ˆì§¸_ê°€ê¹Œìš´_ì—­_í˜¸ì„ ', '1ë²ˆì§¸_ê°€ê¹Œìš´_ì—­_ê±°ë¦¬', '5ë¶„ì´í•˜_ì—­_ê°œìˆ˜', '5ë¶„ì´ˆê³¼_10ë¶„ì´í•˜_ì—­_ê°œìˆ˜']\n",
    "test = test[selected_feature_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•„íŒŒíŠ¸ëª…               0.0\n",
      "ì „ìš©ë©´ì (ã¡)            0.0\n",
      "ê³„ì•½ë…„ì›”               0.0\n",
      "ì¸µ                  0.0\n",
      "ê±´ì¶•ë…„ë„               0.0\n",
      "êµ¬                  0.0\n",
      "ë™                  0.0\n",
      "ë„ë¡œëª…                0.0\n",
      "ì„¸ëŒ€ë³„ì£¼ì°¨ëŒ€ìˆ˜            0.0\n",
      "ì¢Œí‘œX                0.0\n",
      "ì¢Œí‘œY                0.0\n",
      "top_apt            0.0\n",
      "êµ­ë¯¼í‰ìˆ˜               0.0\n",
      "1ë²ˆì§¸_ê°€ê¹Œìš´_ì—­_ì´ë¦„       0.0\n",
      "1ë²ˆì§¸_ê°€ê¹Œìš´_ì—­_í˜¸ì„        0.0\n",
      "1ë²ˆì§¸_ê°€ê¹Œìš´_ì—­_ê±°ë¦¬       0.0\n",
      "5ë¶„ì´í•˜_ì—­_ê°œìˆ˜          0.0\n",
      "5ë¶„ì´ˆê³¼_10ë¶„ì´í•˜_ì—­_ê°œìˆ˜    0.0\n"
     ]
    }
   ],
   "source": [
    "impute_missing_values(test)\n",
    "\n",
    "print((test.isnull().mean() * 100).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting using XGBoost...\n"
     ]
    }
   ],
   "source": [
    "# ìµœì¢… ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ\n",
    "def train_and_predict(model_class, best_params):\n",
    "    model = model_class(**best_params)\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "    pipeline.fit(X, y)\n",
    "    predictions = pipeline.predict(test)\n",
    "    return predictions.astype(int)  # ì˜ˆì¸¡ê°’ì„ intë¡œ ë³€í™˜\n",
    "\n",
    "# ì˜ˆì¸¡ ë° ì €ì¥\n",
    "print(\"Predicting using XGBoost...\")\n",
    "xgb_predictions = train_and_predict(XGBRegressor, xgb_best_params)\n",
    "submission_xgb = pd.DataFrame({\n",
    "    'target': xgb_predictions\n",
    "})\n",
    "submission_xgb.to_csv(f'test_xgb_11059.5517.csv', index=False)\n",
    "\n",
    "# print(\"Predicting using CatBoost...\")\n",
    "# cat_predictions = train_and_predict(CatBoostRegressor, cat_best_params)\n",
    "# submission_cat = pd.DataFrame({\n",
    "#     'target': cat_predictions\n",
    "# })\n",
    "# submission_cat.to_csv(f'test_cat_13919.0407.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helpotcreator-zEEQU_7F-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
